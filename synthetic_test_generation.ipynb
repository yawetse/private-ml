{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d65b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import DPSDA components\n",
    "from pe.data import TextCSV\n",
    "from pe.logging import setup_logging\n",
    "from pe.runner import PE\n",
    "from pe.population import PEPopulation\n",
    "from pe.api.text import LLMAugPE\n",
    "from pe.llm import OpenAILLM\n",
    "from pe.embedding.text import SentenceTransformer\n",
    "from pe.histogram import NearestNeighbors\n",
    "from pe.callback import SaveTextToCSV\n",
    "from pe.logger import CSVPrint\n",
    "from pe.logger import LogPrint\n",
    "\n",
    "# Configure pandas behavior\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Configuration\n",
    "# Set up paths, load environment variables (including the OpenAI API key), and configure logging.\n",
    "\n",
    "# %%\n",
    "# Define the output folder for results\n",
    "exp_folder = \"results/text/synthetic_transcripts\"\n",
    "# Get the directory of the current script/notebook\n",
    "current_folder = os.path.dirname(os.path.abspath(\"__file__\")) # Use __file__ for script context; adjust if running interactively without saving\n",
    "\n",
    "# Create the results directory if it doesn't exist\n",
    "os.makedirs(exp_folder, exist_ok=True)\n",
    "os.makedirs(os.path.join(exp_folder, \"synthetic_text\"), exist_ok=True) # Create subfolder for CSV output\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Setup logging to file and console\n",
    "setup_logging(log_file=os.path.join(exp_folder, \"log.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9ddb3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TextData' from 'pe.data' (/Users/yawetse/Developer/github/yawetse/private-ml/.venv/lib/python3.13/site-packages/pe/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextData\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ## Load Data\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load the call transcripts from the specified CSV file.\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Specify the path to your CSV file\u001b[39;00m\n\u001b[32m      9\u001b[39m csv_file_path = \u001b[33m'\u001b[39m\u001b[33mreal_estate_synthetic_data/basic_call_transcripts.csv\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;66;03m# <<< CHANGE THIS TO YOUR CSV FILENAME\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'TextData' from 'pe.data' (/Users/yawetse/Developer/github/yawetse/private-ml/.venv/lib/python3.13/site-packages/pe/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from pe.data import TextData\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Load Data\n",
    "# Load the call transcripts from the specified CSV file.\n",
    "\n",
    "# %%\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = 'real_estate_synthetic_data/basic_call_transcripts.csv' # <<< CHANGE THIS TO YOUR CSV FILENAME\n",
    "\n",
    "# Load the CSV using pandas\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    # Extract the 'TranscriptText' column into a list\n",
    "    real_texts = df['TranscriptText'].tolist()\"\"\n",
    "    print(f\"Successfully loaded {len(real_texts)} transcripts from {csv_file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {csv_file_path}. Please check the path.\")\n",
    "    # Exit or handle error appropriately in a real script\n",
    "    real_texts = [] # Assign empty list to avoid downstream errors in notebook context\n",
    "except KeyError:\n",
    "    print(f\"Error: 'TranscriptText' column not found in {csv_file_path}. Please check the column name.\")\n",
    "    real_texts = []\n",
    "\n",
    "# Create a DPSDA TextData object\n",
    "if real_texts:\n",
    "    data = TextData(texts=real_texts)\n",
    "    num_private_samples = len(data.data_frame)\n",
    "    print(f\"Created TextData object with {num_private_samples} samples.\")\n",
    "else:\n",
    "    print(\"Cannot proceed without loaded data.\")\n",
    "    # In a real scenario, you might stop execution here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc12cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## Initialize DPSDA Components\n",
    "# Configure and initialize the components needed for the Private Evolution process:\n",
    "# * **LLM:** The language model interface (OpenAI GPT-4o-mini).\n",
    "# * **API:** The text augmentation API using the LLM.\n",
    "# * **Embedding:** A sentence transformer model for text representation.\n",
    "# * **Histogram:** The mechanism for density estimation (Nearest Neighbors).\n",
    "# * **Population:** Manages the synthetic population during evolution.\n",
    "\n",
    "# %%\n",
    "# Check if data was loaded successfully before proceeding\n",
    "if real_texts:\n",
    "    # Configure the OpenAI LLM\n",
    "    # Model: gpt-4o-mini (as used in the example script update)\n",
    "    # Temperature: Controls randomness (higher means more random)\n",
    "    # Num_threads: Parallel API calls\n",
    "    llm = OpenAILLM(\n",
    "        max_completion_tokens=128,\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        temperature=1.4,\n",
    "        num_threads=4 # Adjust based on your OpenAI rate limits and CPU\n",
    "    )\n",
    "    print(\"Initialized OpenAILLM.\")\n",
    "\n",
    "    # Configure the LLM Augmentation API\n",
    "    # Requires prompt template files (download from DPSDA repo)\n",
    "    random_prompt_path = os.path.join(current_folder, \"random_api_prompt.json\")\n",
    "    variation_prompt_path = os.path.join(current_folder, \"variation_api_prompt.json\")\n",
    "\n",
    "    if not os.path.exists(random_prompt_path) or not os.path.exists(variation_prompt_path):\n",
    "         print(f\"Error: Prompt files not found. Make sure 'random_api_prompt.json' and 'variation_api_prompt.json' are in the directory: {current_folder}\")\n",
    "         # Handle error appropriately\n",
    "    else:\n",
    "        api = LLMAugPE(\n",
    "            llm=llm,\n",
    "            random_api_prompt_file=random_prompt_path,\n",
    "            variation_api_prompt_file=variation_prompt_path,\n",
    "            min_word_count=25, # Minimum words for generated text\n",
    "            word_count_std=20, # Standard deviation for word count target\n",
    "            token_to_word_ratio=1.2, # Estimated ratio for token calculation\n",
    "            max_completion_tokens_limit=1200, # Limit for LLM generation\n",
    "            blank_probabilities=0.5, # Probability for blanking parts of prompts\n",
    "        )\n",
    "        print(\"Initialized LLMAugPE.\")\n",
    "\n",
    "        # Configure the Sentence Transformer for embeddings\n",
    "        # 'stsb-roberta-base-v2' is a common choice for semantic similarity\n",
    "        embedding = SentenceTransformer(model=\"stsb-roberta-base-v2\")\n",
    "        print(\"Initialized SentenceTransformer embedding.\")\n",
    "\n",
    "        # Configure the Nearest Neighbors histogram\n",
    "        histogram = NearestNeighbors(\n",
    "            embedding=embedding,\n",
    "            mode=\"L2\", # Use L2 distance (Euclidean)\n",
    "            lookahead_degree=0, # Parameter for histogram construction\n",
    "        )\n",
    "        print(\"Initialized NearestNeighbors histogram.\")\n",
    "\n",
    "        # Configure the PE Population\n",
    "        population = PEPopulation(\n",
    "            api=api,\n",
    "            initial_variation_api_fold=3, # Folds for initial variations\n",
    "            next_variation_api_fold=3, # Folds for subsequent variations\n",
    "            keep_selected=True, # Keep selected samples in population\n",
    "            selection_mode=\"rank\" # Selection strategy\n",
    "        )\n",
    "        print(\"Initialized PEPopulation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8572f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## Setup Callbacks and Loggers\n",
    "# Configure components that run during or after the PE process:\n",
    "# * **SaveTextToCSV:** Saves the generated synthetic text to CSV files.\n",
    "# * **CSVPrint/LogPrint:** Log progress and metrics.\n",
    "\n",
    "# %%\n",
    "if real_texts:\n",
    "    # Callback to save synthetic data periodically (or at the end)\n",
    "    save_text_to_csv = SaveTextToCSV(\n",
    "        output_folder=os.path.join(exp_folder, \"synthetic_text\")\n",
    "    )\n",
    "    print(\"Configured SaveTextToCSV callback.\")\n",
    "\n",
    "    # Loggers for console and CSV output\n",
    "    csv_print = CSVPrint(output_folder=exp_folder)\n",
    "    log_print = LogPrint()\n",
    "    print(\"Configured loggers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a08dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## Run Private Evolution\n",
    "# Initialize the main `PE` runner and execute the generation process.\n",
    "# * `num_samples_schedule`: Defines how many synthetic samples to generate. Here, we generate 5000 in one go.\n",
    "# * `delta`: Differential privacy parameter, often set based on the dataset size.\n",
    "# * `epsilon`: Differential privacy parameter (privacy budget).\n",
    "\n",
    "# %%\n",
    "if real_texts and 'data' in locals() and 'population' in locals() and 'histogram' in locals():\n",
    "    # Calculate delta based on the number of private samples\n",
    "    # This is a common heuristic for setting delta in DP\n",
    "    delta = 1.0 / num_private_samples / np.log(num_private_samples)\n",
    "    print(f\"Calculated delta: {delta}\")\n",
    "\n",
    "    # Initialize the PE runner\n",
    "    pe_runner = PE(\n",
    "        priv_data=data,\n",
    "        population=population,\n",
    "        histogram=histogram,\n",
    "        callbacks=[save_text_to_csv], # Add other callbacks if needed (e.g., ComputeFID)\n",
    "        loggers=[csv_print, log_print],\n",
    "    )\n",
    "    print(\"Initialized PE runner.\")\n",
    "\n",
    "    # Run the PE process\n",
    "    print(\"Starting Private Evolution process to generate 5000 samples...\")\n",
    "    pe_runner.run(\n",
    "        num_samples_schedule=[5000], # Generate 5000 samples in one generation step\n",
    "        delta=delta,\n",
    "        epsilon=1.0, # Set your desired privacy budget (epsilon)\n",
    "        checkpoint_path=None, # Disable checkpointing for this simple run\n",
    "    )\n",
    "    print(f\"Finished PE process. Synthetic data saved in: {os.path.join(exp_folder, 'synthetic_text')}\")\n",
    "else:\n",
    "    print(\"Skipping PE run due to errors in previous steps (data loading or component initialization).\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
